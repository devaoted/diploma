{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPS6SxO9ktRmfAG/krVkRDu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lXldYmwJiadn","executionInfo":{"status":"ok","timestamp":1679909581461,"user_tz":-180,"elapsed":3203,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"outputs":[],"source":["import warnings \n","warnings.filterwarnings('ignore')\n","import shutil\n","import os \n","from skimage import io\n","import numpy as np\n","import matplotlib.pyplot as plt \n","import random\n","from PIL import Image\n","from torch.autograd import Variable \n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","import pandas as pd\n","import copy\n","import gc\n"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch.nn as nn\n","import torchvision"],"metadata":{"id":"Pm1Z64wplrO5","executionInfo":{"status":"ok","timestamp":1679909581463,"user_tz":-180,"elapsed":13,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XML1LBfilrRn","executionInfo":{"status":"ok","timestamp":1679909607423,"user_tz":-180,"elapsed":25971,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}},"outputId":"30ac86e3-3005-4e2d-80f8-e3d6afa2cf34"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Функция для обучения "],"metadata":{"id":"OIOKcqcauPb1"}},{"cell_type":"code","source":["\n","def train( model, criterion,  optimizer, train_dataloader, val_dataloader, num_epochs ):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    torch.backends.cuda.cufft_plan_cache.clear()\n","    \n","    # Define your execution device\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    #print(\"The model will be running on\", device, \"device\")\n","    # Convert model parameters and buffers to CPU or Cuda\n","    model.to(device)\n","    \n","    best_metric = 0\n","    best_accuracy_test = 0\n","    best_accuracy_train = 0\n","\n","    loss_train_hist = []\n","    loss_val_hist = []\n","    accuracy_train_hist = []\n","    accuracy_val_hist = []\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for i in train_dataloader:\n","            \n","            \n","            \n","        \n","            lbl = Variable(torch.nn.functional.one_hot(i['lbl'],num_classes=2).to(device)) \n","            data = Variable(i['data'].to(device))\n","\n","            \n","            outputs = model.forward(data) #forward pass\n","            optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n"," \n","            # obtain the loss functio\n","        \n","        \n","        \n","            loss = criterion(outputs, lbl.float())\n","\n","\n","        \n","        \n"," \n","            loss.backward() #calculates the loss of the loss function\n"," \n","            optimizer.step() #improve from loss, i.e backprop\n","    \n","    \n","    \n","        model.eval()\n","        preds = []\n","        lbls = []\n","        for i in val_dataloader:\n","            \n","            \n","            \n","        \n","            lbl = list(np.array(i['lbl']))\n","            lbls = lbls + lbl\n","    \n","            outputs = list(np.array(model.forward(Variable(i['data'].to(device))).argmax(1).cpu())) #forward pass\n","            preds = preds + outputs\n","        \n","        \n","        \n","    \n","     \n","        loss = float(criterion(torch.nn.functional.one_hot(torch.tensor(lbls),num_classes=2).float(),\n","                           torch.nn.functional.one_hot(torch.tensor(preds), num_classes=2).float()))\n","        test_acc = accuracy_score(lbls, preds)\n","\n","        loss_val_hist.append(loss)\n","        accuracy_val_hist.append(test_acc)\n","    \n","        \n","    \n","        #print(f'Точность на валедации на эпохе {epoch+1} = {acc}')\n","        #print(f'Loss на валедации на эпохе {epoch+1} = {loss}')\n","    \n","        if test_acc > best_accuracy_test:\n","        \n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            best_accuracy_test = test_acc\n","    \n","        preds = []\n","        lbls = []\n","        for i in train_dataloader:\n","        \n","        \n","            \n","            lbl = list(np.array(i['lbl']))\n","            lbls = lbls + lbl\n","    \n","            outputs = list(np.array(model.forward(Variable(i['data'].to(device))).argmax(1).cpu())) #forward pass\n","            preds = preds + outputs\n","        \n","        \n","        \n","    \n","     \n","        loss = float(criterion(torch.nn.functional.one_hot(torch.tensor(lbls),num_classes=2).float(),\n","                           torch.nn.functional.one_hot(torch.tensor(preds), num_classes=2).float()))\n","    \n","        train_acc = accuracy_score(lbls, preds)\n","    \n","        loss_train_hist.append(loss)\n","        accuracy_train_hist.append(train_acc)\n","\n","        if train_acc>best_accuracy_train:\n","\n","          best_accuracy_train = train_acc\n","\n","\n","        if test_acc == best_accuracy_test:\n","\n","          if  train_acc>=best_accuracy_train:\n","\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","        #print(f'Точность на трейне на эпохе {epoch+1} = {acc}')\n","        #print(f'Loss на трейне на эпохе {epoch+1} = {loss}')\n","\n","    return best_model_wts\n"],"metadata":{"id":"IB90Bdj9uOY8","executionInfo":{"status":"ok","timestamp":1679909607425,"user_tz":-180,"elapsed":26,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Метрики"],"metadata":{"id":"6bh8ZK3Qoyj6"}},{"cell_type":"code","source":["def get_metrics(lbl, pred):\n","\n","  return [round(accuracy_score(lbl, pred),3), round(precision_score(lbl, pred),3), round(recall_score(lbl, pred),3), round(f1_score(lbl, pred),3), round(roc_auc_score(lbl, pred),3)]\n","  "],"metadata":{"id":"lN58SioBoxso","executionInfo":{"status":"ok","timestamp":1679909607425,"user_tz":-180,"elapsed":24,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Финальный тест модели "],"metadata":{"id":"_wJHu3HAv9xh"}},{"cell_type":"code","source":["def final_test_of_model(model, train_dataloader, val_dataloader):\n","\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  model.to(device)\n","\n","  preds = []\n","  lbls = []\n","  model.eval()\n","  for i in train_dataloader:\n","\n","\n","    lbl = list(np.array(i['lbl']))\n","    lbls = lbls + lbl\n","    \n","    outputs = list(np.array(model.forward(Variable(i['data'].to(device))).argmax(1).cpu())) #forward pass\n","    preds = preds + outputs\n","        \n","        \n","        \n","    \n","     \n","    \n","    \n","  train_metrics = get_metrics(lbls, preds)\n","\n","\n","  preds = []\n","  lbls = []\n","  for i in val_dataloader:\n","\n","\n","    lbl = list(np.array(i['lbl']))\n","    lbls = lbls + lbl\n","    \n","    outputs = list(np.array(model.forward(Variable(i['data'].to(device))).argmax(1).cpu())) #forward pass\n","    preds = preds + outputs\n","\n","\n","  test_metrics = get_metrics(lbls, preds)\n","\n","  return train_metrics, test_metrics\n","\n","  \n","\n","  \n","\n","\n","    \n","        "],"metadata":{"id":"4HMqWT7Dv872","executionInfo":{"status":"ok","timestamp":1679909607426,"user_tz":-180,"elapsed":23,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Запись результатов в файл и копирование файла на гугл диск "],"metadata":{"id":"S2hYScBs2PPd"}},{"cell_type":"code","source":["def write_and_copy_results(train_metrics, test_metrics, extract_info, model_name):\n","\n","  file = open(f\"/content/results/{extract_info}_{model_name}.txt\", \"w\")\n","\n","\n","  file.write(f\" accuracy_score on train data = {train_metrics[0]} \\n\")\n","  file.write(f\" precision_score on train data = {train_metrics[1]} \\n\")\n","  file.write(f\" recall_score on train data = {train_metrics[2]} \\n\")\n","  file.write(f\" f1_score on train data = {train_metrics[3]} \\n\")\n","  file.write(f\" roc_auc_score on train data = {train_metrics[4]} \\n\\n\")\n","\n","\n","  file.write(f\" accuracy_score on test data = {test_metrics[0]} \\n\")\n","  file.write(f\" precision_score on test data = {test_metrics[1]} \\n\")\n","  file.write(f\" recall_score on test data = {test_metrics[2]} \\n\")\n","  file.write(f\" f1_score on test data = {test_metrics[3]} \\n\")\n","  file.write(f\" roc_auc_score on test data = {test_metrics[4]} \\n\\n\")\n","  \n","\n","  file.close()\n","\n","\n","  shutil.copyfile(f\"/content/results/{extract_info}_{model_name}.txt\",f\"/content/drive/MyDrive/CNN_LSTM/results/{extract_info}_{model_name}.txt\")\n"],"metadata":{"id":"jV7SgdEn2Ta6","executionInfo":{"status":"ok","timestamp":1679909607427,"user_tz":-180,"elapsed":23,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Bi-lstm"],"metadata":{"id":"LdVofu-Zm_iS"}},{"cell_type":"code","source":["class Bi_LSTM(nn.Module):\n","    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n","        super(Bi_LSTM, self).__init__()\n","        self.num_classes = num_classes #number of classes\n","        self.num_layers = num_layers #number of layers\n","        self.input_size = input_size #input size\n","        self.hidden_size = hidden_size #hidden state\n","        self.seq_length = seq_length #sequence length\n","\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n","                          num_layers=num_layers, batch_first=True, bidirectional =True) #lstm\n","        self.fc_1 =  nn.Linear(self.hidden_size*2*self.num_layers, self.hidden_size*2*self.num_layers)\n","        \n","\n","        #self.fc_1 =  nn.Linear(self.hidden_size*2, 1024) #fully connected 1\n","        self.fc_out = nn.Linear( self.hidden_size*2*self.num_layers,num_classes) #fully connected last layer\n","\n","        self.relu = nn.ReLU()\n","        self.drop1 = nn.Dropout(p=0.5)\n","        self.drop2 = nn.Dropout(p=0.1)\n","\n","        self.softmax = nn.Softmax()\n","    \n","    def forward(self,x):\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        h_0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)) #hidden state\n","        c_0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)) #internal state\n","        # Propagate input through LSTM\n","        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n","        \n","        hn = hn.view(-1, self.hidden_size*2*self.num_layers) #reshaping the data for Dense layer next\n","        out = self.relu(hn)\n","        \n","        #out=self.relu(output[:,-1,:])\n","        out = self.drop2(out)\n","        out = self.fc_1(out) #first Dense\n","        out = self.relu(out) #relu\n","        out = self.drop1(out)\n","        \n","        out = self.fc_out(out) #Final Output\n","        return out"],"metadata":{"id":"UyJW3gsrm-zl","executionInfo":{"status":"ok","timestamp":1679909607428,"user_tz":-180,"elapsed":22,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class LSTM(nn.Module):\n","    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n","        super(LSTM, self).__init__()\n","        self.num_classes = num_classes #number of classes\n","        self.num_layers = num_layers #number of layers\n","        self.input_size = input_size #input size\n","        self.hidden_size = hidden_size #hidden state\n","        self.seq_length = seq_length #sequence length\n","\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n","                          num_layers=num_layers, batch_first=True, bidirectional =False) #lstm\n","        self.fc_1 =  nn.Linear(self.hidden_size*self.num_layers, self.hidden_size*2*self.num_layers)\n","        \n","\n","        #self.fc_1 =  nn.Linear(self.hidden_size*2, 1024) #fully connected 1\n","        self.fc_out = nn.Linear( self.hidden_size*2*self.num_layers,num_classes) #fully connected last layer\n","\n","        self.relu = nn.ReLU()\n","        self.drop1 = nn.Dropout(p=0.5)\n","        self.drop2 = nn.Dropout(p=0.1)\n","\n","        self.softmax = nn.Softmax()\n","    \n","    def forward(self,x):\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)) #hidden state\n","        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)) #internal state\n","        # Propagate input through LSTM\n","        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n","        \n","        hn = hn.view(-1, self.hidden_size*self.num_layers) #reshaping the data for Dense layer next\n","        out = self.relu(hn)\n","        \n","        #out=self.relu(output[:,-1,:])\n","        out = self.drop2(out)\n","        out = self.fc_1(out) #first Dense\n","        out = self.relu(out) #relu\n","        out = self.drop1(out)\n","        \n","        out = self.fc_out(out) #Final Output\n","        return out"],"metadata":{"id":"qxUMnPxVI76d","executionInfo":{"status":"ok","timestamp":1679909607429,"user_tz":-180,"elapsed":22,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Поиск параметров "],"metadata":{"id":"aVMrNOiNmdXh"}},{"cell_type":"code","source":["def search_params(dict_of_datasets):\n","\n","\n","  \n","  \n","  for i in list(dict_of_datasets.keys()):\n","\n","\n","    print(i)\n","    train_dataloader_extracted = DataLoader(Make_extracted_Dataset({'data':torch.load(dict_of_datasets[i][0]),'lbl':torch.load(dict_of_datasets[i][1])}),batch_size=8)\n","    test_dataloader_extracted = DataLoader(Make_extracted_Dataset({'data':torch.load(dict_of_datasets[i][2]),'lbl':torch.load(dict_of_datasets[i][3])}))\n","\n","    for k in ['LSTM','Bi_LSTM']:\n","      \n","      print(k)\n","      num_epochs = 1000 \n","      learning_rate = 0.00001 \n","\n","      input_size =  dict_of_datasets[i][4]#number of features\n","      hidden_size = 1000 #number of features in hidden state\n","      num_layers = dict_of_datasets[i][5] #number of stacked lstm layers\n","\n","      num_classes = 2\n","\n","\n","      if k == 'LSTM':\n","\n","        \n","\n","        model = LSTM(num_classes, input_size, hidden_size, num_layers, dict_of_datasets[i][5]) #our lstm class \n","\n","\n","      else:\n","\n","\n","        model = Bi_LSTM(num_classes, input_size, hidden_size, num_layers, dict_of_datasets[i][5]) \n","\n","\n","      criterion = torch.nn.CrossEntropyLoss()    \n","      optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate,weight_decay=0.001) \n","      number_of_frames=dict_of_datasets[i][5]\n","\n","      best_model_wts  = train(model, criterion, optimizer, train_dataloader_extracted, test_dataloader_extracted, num_epochs)\n","\n","      model.load_state_dict(best_model_wts)\n","\n","      train_metrics, test_metrics = final_test_of_model(model, train_dataloader_extracted, test_dataloader_extracted)\n","\n","\n","      write_and_copy_results(train_metrics, test_metrics, i, k)\n","\n","\n","\n","\n","\n","\n","\n","\n","      \n","\n","\n","\n","\n","\n","\n","\n","      \n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"zTKEnnA-mccv","executionInfo":{"status":"ok","timestamp":1679909607431,"user_tz":-180,"elapsed":23,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Данные"],"metadata":{"id":"DvkmI24bmFn1"}},{"cell_type":"code","source":["class Make_extracted_Dataset(Dataset):\n","\n","    def __init__(self, my_dict, ):\n","        \n","        self.my_dict = my_dict\n","       \n","\n","    def __len__(self):\n","        \n","        #Размер сета\n","        return len(self.my_dict['lbl'])\n","\n","        \n","        \n","    # Получаем 1 набор данных                                                         \n","    def __getitem__(self, idx):\n","        \n","        if torch.is_tensor(idx):\n","                idx = idx.tolist()\n","                \n","        \n","        sample = {'data':self.my_dict['data'][idx], 'lbl': self.my_dict['lbl'][idx]}\n","            \n","            \n","       \n","\n","        \n","\n","        return sample"],"metadata":{"id":"yZBxtqa4mQtO","executionInfo":{"status":"ok","timestamp":1679909607431,"user_tz":-180,"elapsed":22,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def creat_extracted_dataset(extraktor, dataset,size,number_of_frames):\n","    \n","    lbls = []\n","    inputs = []\n","    for i in dataset:\n","        \n","        extracketed_input = [extraktor(i['data'][k].reshape((number_of_frames,3,720,1280)).float())\\\n","                             .detach().numpy() for k in range(len(i['data']))]\n","        \n","        extracketed_input = torch.tensor(extracketed_input).reshape((i['data'].shape[0],number_of_frames,size))\n","        \n","        \n","        \n","        \n","        \n","        \n","        lbls = lbls +list(i['lbl'])\n","        inputs = inputs + list(np.array(extracketed_input))\n","    \n","    return  np.array(inputs),np.array(lbls),\n","        \n","\n"],"metadata":{"id":"T_13JHroD864","executionInfo":{"status":"ok","timestamp":1679909607432,"user_tz":-180,"elapsed":22,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","# Прописываем путь к файлу с архивом\n","zip_file = '/content/drive/MyDrive/CNN_LSTM/extracted_datasets.zip'\n","\n","# Распаковываем архив\n","z = zipfile.ZipFile(zip_file, 'r')\n","z.extractall()\n"],"metadata":{"id":"p5FaRTGplrS4","executionInfo":{"status":"ok","timestamp":1679909609342,"user_tz":-180,"elapsed":1932,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Перебор"],"metadata":{"id":"UWcEpru7moNg"}},{"cell_type":"code","source":["os.mkdir('results')"],"metadata":{"id":"tSedZJr78qzp","executionInfo":{"status":"ok","timestamp":1679909609345,"user_tz":-180,"elapsed":24,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ключ имя конфигурации - значение: Путь до данных обучающей выборки , путь до меток обучающей выборки , \n","                                  # путь до данных тестовой выборки , путь до меток тестовой выборки , \n","                                  # размер выхода экстрактора, количество кадров\n","                                  \n","dir_with_datasets = '/content/extracted_datasets/'\n","\n","dict_of_datasets = {\n","      \n","      'alexnet_10_frames' : [dir_with_datasets + 'train_alexnet_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'train_alexnet_number_of_frames_10_lbl.pt',\n","                             dir_with_datasets + 'test_alexnet_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'test_alexnet_number_of_frames_10_lbl.pt',\n","                             1000, 10],\n","                      \n","      'alexnet_5_frames' : [dir_with_datasets + 'train_alexnet_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'train_alexnet_number_of_frames_5_lbl.pt',\n","                             dir_with_datasets + 'test_alexnet_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'test_alexnet_number_of_frames_5_lbl.pt',\n","                             1000, 5],\n","                      \n","\n","      'resnet152_10_frames' : [dir_with_datasets + 'train_resnet152_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'train_resnet152_number_of_frames_10_lbl.pt',\n","                             dir_with_datasets + 'test_resnet152_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'test_resnet152_number_of_frames_10_lbl.pt',\n","                             2048, 10],\n","                      \n","      'resnet152_5_frames' : [dir_with_datasets + 'train_resnet152_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'train_resnet152_number_of_frames_5_lbl.pt',\n","                             dir_with_datasets + 'test_resnet152_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'test_resnet152_number_of_frames_5_lbl.pt',\n","                             2048, 5],\n","                      \n","\n","\n","      'vgg16_10_frames' : [dir_with_datasets + 'train_vgg16_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'train_vgg16_number_of_frames_10_lbl.pt',\n","                             dir_with_datasets + 'test_vgg16_number_of_frames_10_data.pt',\n","                             dir_with_datasets + 'test_vgg16_number_of_frames_10_lbl.pt',\n","                             1000, 10],\n","                      \n","      'vgg16_5_frames' : [dir_with_datasets + 'train_vgg16_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'train_vgg16_number_of_frames_5_lbl.pt',\n","                             dir_with_datasets + 'test_vgg16_number_of_frames_5_data.pt',\n","                             dir_with_datasets + 'test_vgg16_number_of_frames_5_lbl.pt',\n","                             1000, 5]\n","\n","                            }\n"],"metadata":{"id":"FsImW2q51TAk","executionInfo":{"status":"ok","timestamp":1679909609350,"user_tz":-180,"elapsed":26,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["search_params(dict_of_datasets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlW7OtD21TQV","outputId":"4f5fc75a-dd0d-485b-c623-e8f3796a127a","executionInfo":{"status":"ok","timestamp":1679918832013,"user_tz":-180,"elapsed":9222687,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["alexnet_10_frames\n","LSTM\n","Bi_LSTM\n","alexnet_5_frames\n","LSTM\n","Bi_LSTM\n","resnet152_10_frames\n","LSTM\n","Bi_LSTM\n","resnet152_5_frames\n","LSTM\n","Bi_LSTM\n","vgg16_10_frames\n","LSTM\n","Bi_LSTM\n","vgg16_5_frames\n","LSTM\n","Bi_LSTM\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Bti7iWOFX5Tz","executionInfo":{"status":"ok","timestamp":1679918832014,"user_tz":-180,"elapsed":39,"user":{"displayName":"пётр смирнов","userId":"07731969239387225665"}}},"execution_count":16,"outputs":[]}]}